{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "o8mi475EetDQ",
        "outputId": "b4cd5c86-c242-496e-e12f-4f776dd02490"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet_pytorch) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet_pytorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet_pytorch\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=9882bd3ed7fe393a9ae147a0169710f24685909be7d20f86f3b792f185fbbcf8\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "Successfully built efficientnet_pytorch\n",
            "Installing collected packages: efficientnet_pytorch\n",
            "Successfully installed efficientnet_pytorch-0.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install efficientnet_pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AkuTzTXIWK4"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MYPso14AF_S2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torchvision.datasets as datasets\n",
        "from efficientnet_pytorch import EfficientNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdvjKdK2IZmF"
      },
      "source": [
        "# Define data transforms (Augmentation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EhffE_SYglYS"
      },
      "outputs": [],
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo-6xMN5IfAA"
      },
      "source": [
        "# Download CIFAR-10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ffioycxYGMuO",
        "outputId": "4b75d8dd-fe7f-49bc-ff13-d5cd52466caf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "valset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_val)\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "# Split trainset into train and validation sets\n",
        "train_size = int(0.8 * len(trainset))\n",
        "val_size = len(trainset) - train_size\n",
        "train_dataset, val_dataset = random_split(trainset, [train_size, val_size])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-OQse5f8dFM"
      },
      "source": [
        "# Train Val Data Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1Zg4zJ1YQfi_",
        "outputId": "89ffc6f4-692f-4276-ec2f-7205a566996c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples in train set: 40000\n",
            "Number of samples in validation set: 10000\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "# Define indices for stratified sampling\n",
        "indices = np.arange(len(trainset))\n",
        "targets = np.array(trainset.targets)\n",
        "\n",
        "# Stratified split for train-validation sets\n",
        "stratified_splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "train_indices, val_indices = next(stratified_splitter.split(indices, targets))\n",
        "\n",
        "# Create train and validation datasets using the sampled indices\n",
        "train_dataset = torch.utils.data.Subset(trainset, train_indices)\n",
        "val_dataset = torch.utils.data.Subset(trainset, val_indices)\n",
        "\n",
        "print(f\"Number of samples in train set: {len(train_dataset)}\")\n",
        "print(f\"Number of samples in validation set: {len(val_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DltDYdPH8Wo8"
      },
      "source": [
        "# Define Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "toA307ioQhQt"
      },
      "outputs": [],
      "source": [
        "k = 256\n",
        "\n",
        "trainloader = DataLoader(train_dataset, batch_size=k, shuffle=True)\n",
        "valloader = DataLoader(val_dataset, batch_size=k, shuffle=False)\n",
        "testloader = DataLoader(testset, batch_size=k, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3r76cskIjdx"
      },
      "source": [
        "# Load Pretrained Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Nov7nWcfGU2O",
        "outputId": "af311262-a00e-40a1-d8f1-8e9ea7271be0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained weights for efficientnet-b0\n"
          ]
        }
      ],
      "source": [
        "# Load pretrained ResNet-50\n",
        "resnet = models.resnet50(pretrained=True)\n",
        "num_ftrs = resnet.fc.in_features\n",
        "resnet.fc = nn.Linear(num_ftrs, 10)  # Change the output layer to match CIFAR-10 classes\n",
        "\n",
        "# Load pretrained EfficientNet-b0\n",
        "efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "num_ftrs = efficientnet._fc.in_features\n",
        "efficientnet._fc = nn.Linear(num_ftrs, 10)  # Change the output layer to match CIFAR-10 classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6Ow69JMI9DF"
      },
      "source": [
        "# Define Loss Function, Optimizer and learning rate scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Ox2N-4ftGdOG"
      },
      "outputs": [],
      "source": [
        "criterion = nn.NLLLoss()\n",
        "lr = 0.001\n",
        "optimizer_resnet = optim.SGD(resnet.parameters(), lr=lr, momentum=0.9)\n",
        "optimizer_efficientnet = optim.SGD(efficientnet.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "scheduler_resnet = optim.lr_scheduler.StepLR(optimizer_resnet, step_size=3, gamma=0.1)\n",
        "scheduler_efficientnet = optim.lr_scheduler.StepLR(optimizer_efficientnet, step_size=3, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV4V0ns9IuIF"
      },
      "source": [
        "# Define Training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "aeZyKz6CGXNd"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, trainloader, valloader, num_epochs=5):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in trainloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in valloader:\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_accuracy = 100 * correct / total\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "        # Adjust learning rate\n",
        "        scheduler.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntYEtIgu17FA"
      },
      "source": [
        "# Training our models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5F0eY2058OKj"
      },
      "outputs": [],
      "source": [
        "# Train ResNet-50\n",
        "print(\"Training ResNet-50...\")\n",
        "train_model(resnet, criterion, optimizer_resnet, scheduler_resnet, trainloader, valloader)\n",
        "\n",
        "# Train EfficientNet-b0\n",
        "print(\"\\nTraining EfficientNet-b0...\")\n",
        "train_model(efficientnet, criterion, optimizer_efficientnet, scheduler_efficientnet, trainloader, valloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SOE8qjqI2JW"
      },
      "source": [
        "# Define function to calculate test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WnDqMfEvAEoH"
      },
      "outputs": [],
      "source": [
        "def test_accuracy(model, testloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blz8uVbI2CUZ"
      },
      "source": [
        "# Testing our models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKY88N7c1_6w"
      },
      "outputs": [],
      "source": [
        "# Test ResNet-50\n",
        "resnet_test_accuracy = test_accuracy(resnet, testloader)\n",
        "print(f\"Test Accuracy of ResNet-50: {resnet_test_accuracy:.2f}%\")\n",
        "\n",
        "# Test EfficientNet-b0\n",
        "efficientnet_test_accuracy = test_accuracy(efficientnet, testloader)\n",
        "print(f\"Test Accuracy of EfficientNet-b0: {efficientnet_test_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Saving our models "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# After training your model...\n",
        "torch.save(resnet.state_dict(), 'resnet50_model.pth')\n",
        "torch.save(efficientnet.state_dict(), 'efficientnet_b0_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Using our saved model of ResNet-50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "image_path = '/content/11.png'\n",
        "image = Image.open(image_path).convert('RGB')  # Ensure RGB format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "\n",
        "def get_resnet50():\n",
        "    model = torchvision.models.resnet50(pretrained=True)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    num_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_features, 10)  # 10 classes for CIFAR10\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = get_resnet50()  # Use the same initialization function as during training\n",
        "model.load_state_dict(torch.load('resnet50_model.pth')) \n",
        "model.eval()  # Set the model to evaluation mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_tensor = transform(image).unsqueeze(0)  # Add a batch dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "image_tensor = image_tensor.to(device)  \n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(image_tensor)\n",
        "    _, predicted = torch.max(outputs.data, 1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]  # Your list of CIFAR10 classes\n",
        "print(f\"Predicted Class: {classes[predicted.item()]}\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Using our saved model of EfficientNet-b0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "def get_efficientnet():\n",
        "    model = torchvision.models.efficientnet_b0(pretrained=True)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    num_features = model.classifier[1].in_features\n",
        "    model.classifier[1] = nn.Linear(num_features, 10) # 10 classes for CIFAR10\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocessing transforms (match your training setup)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = get_efficientnet()\n",
        "model.load_state_dict(torch.load('efficientnet_b0_model.pth'))\n",
        "model.eval()  # Set to evaluation mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_path = '/content/11.png'\n",
        "image = Image.open(image_path).convert('RGB')  \n",
        "image_tensor = transform(image).unsqueeze(0)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "image_tensor = image_tensor.to(device) \n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(image_tensor)\n",
        "    _, predicted = torch.max(outputs.data, 1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "print(f\"Predicted Class: {classes[predicted.item()]}\") "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
